{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VResnet50Scratch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQk_ALuq9J08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import io,transform\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import time\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import transforms, utils,models\n",
        "import copy\n",
        "from skimage import io, transform\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpS2W1WMUbGH",
        "colab_type": "code",
        "outputId": "bd33e7c9-f2e6-4c3c-e362-1bc08b129245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32tgUGZtHEcw",
        "colab_type": "code",
        "outputId": "976b4484-7444-4c0e-e03d-f3475d232738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget http://memorability.csail.mit.edu/lamem.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-08 11:28:41--  http://memorability.csail.mit.edu/lamem.tar.gz\n",
            "Resolving memorability.csail.mit.edu (memorability.csail.mit.edu)... 128.30.195.49\n",
            "Connecting to memorability.csail.mit.edu (memorability.csail.mit.edu)|128.30.195.49|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2708368436 (2.5G) [application/x-gzip]\n",
            "Saving to: ‘lamem.tar.gz’\n",
            "\n",
            "lamem.tar.gz        100%[===================>]   2.52G  12.7MB/s    in 3m 25s  \n",
            "\n",
            "2019-12-08 11:32:07 (12.6 MB/s) - ‘lamem.tar.gz’ saved [2708368436/2708368436]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywwe2qkTH6l2",
        "colab_type": "code",
        "outputId": "602f00fe-530c-4849-ee92-91c18eea46fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfq0TxHhH98a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk2LLq6mHHUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf /content/lamem.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-d-Pf_XG7Fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = pd.read_csv(\"/content/drive/My Drive/image memorability/dataset/train_dataset.csv\")\n",
        "dataset_validation = pd.read_csv(\"/content/drive/My Drive/image memorability/dataset/validation_dataset.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmynr57bG7n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class AsetheticsDataset(Dataset):\n",
        "      '''asethitics dataset'''\n",
        "      def __init__(self,dataframe,root_dir,transform=None):\n",
        "        \"\"\"\n",
        "            Args:\n",
        "                csv_file (string): Path to the csv file with annotations.\n",
        "                root_dir (string): Directory with all the images.\n",
        "                transform (callable, optional): Optional transform to be applied\n",
        "                    on a sample.\n",
        "        \"\"\"\n",
        "        self.data = dataframe\n",
        "        #     self.data.rename(columns=columns,inplace=True)\n",
        "    #     self.data.drop(self.data.columns[[1,2,3,4,5,6,8,9]] , axis=1,inplace=True)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "      def __len__(self):\n",
        "        return len(self.data)\n",
        "  \n",
        "      def __getitem__(self,idx):\n",
        "   \n",
        "        if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "   \n",
        "        image_name =  os.path.join(self.root_dir,self.data.iloc[idx,0])\n",
        "        image = io.imread(image_name)\n",
        "        mem_val = self.data.iloc[idx,1]\n",
        "#     return_sample={}\n",
        "        return_sample = {\n",
        "              'image':image,\n",
        "              'memorability_score':mem_val \n",
        "        }\n",
        "        if self.transform:\n",
        "            return_sample = self.transform(return_sample)\n",
        "    \n",
        "     \n",
        "        return return_sample\n",
        "\n",
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        \n",
        "        image,mem_val = sample['image'], sample[\"memorability_score\"]\n",
        "        \n",
        "        h, w = image.shape[:2]\n",
        "        \n",
        "        # if isinstance(self.output_size, int):\n",
        "        #     if h > w:\n",
        "        #         new_h, new_w = self.output_size * h / w, self.output_size\n",
        "        #     else:\n",
        "        #         new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        # else:\n",
        "        #     new_h, new_w = self.output_size\n",
        "\n",
        "        # new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        img = transform.resize(image, (self.output_size,self.output_size,3))\n",
        "        return {'image': img, 'memorability_score': mem_val}\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        \n",
        "        image, mem_val = sample['image'], sample['memorability_score']\n",
        "#         print(type(torch.from_numpy(image)))\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "#         print(image.shape)\n",
        "      \n",
        "        image = image.transpose((2, 0, 1))\n",
        "        \n",
        "        return {'image': torch.from_numpy(image),\n",
        "                'memorability_score': mem_val}\n",
        "class Normalize(object):\n",
        "    def __init__(self,mean,std):\n",
        "        self.mean=mean\n",
        "        self.std=std\n",
        "    def __call__(self,sample):\n",
        "        image, mem_val = sample[\"image\"], sample[\"memorability_score\"]\n",
        "        normalized=  (image -self.mean) / self.std\n",
        "        return {\n",
        "            \"image\":normalized,\n",
        "            \"memorability_score\" : mem_val\n",
        "       }\n",
        "\n",
        "transformed_dataset_train = AsetheticsDataset(dataset_train,root_dir=\"/content/lamem/images\",\n",
        "                                        transform=transforms.Compose([Rescale(224),ToTensor(),Normalize(0.5,0.5)\n",
        "                                                          ]))\n",
        "\n",
        "transformed_dataset_val= AsetheticsDataset(dataset_validation,root_dir=\"/content/lamem/images\",\n",
        "                                        transform=transforms.Compose([Rescale(224),ToTensor(),Normalize(0.5,0.5)\n",
        "                                                          ]))\n",
        "\n",
        "train_dataloader=DataLoader(transformed_dataset_train,batch_size=32,shuffle=True)\n",
        "validation_dataloader=DataLoader(transformed_dataset_val,batch_size=32,shuffle=True)\n",
        "dataloaders={\n",
        "    \"train\":train_dataloader,\n",
        "    \"val\":validation_dataloader\n",
        "}\n",
        "dataset_sizes ={\n",
        "    \"train\":len(dataset_train),\n",
        "    \"val\":len(dataset_validation)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oIkfNN4Hacu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
        "    since = time.time()\n",
        "    running_loss_history = []\n",
        "    val_running_loss_history=[]\n",
        "    orignal_model=None\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    low_loss = np.inf\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for batched_data in tqdm(dataloaders[phase]):\n",
        "\n",
        "                inputs=batched_data[\"image\"]\n",
        "                inputs = inputs.to(device)\n",
        "                labels=batched_data[\"memorability_score\"]\n",
        "                labels=labels.view(-1,1).double()\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    print(\"  batch loss:    \",loss.item())\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            if phase==\"train\":\n",
        "              running_loss_history.append(epoch_loss)\n",
        "            else:\n",
        "              val_running_loss_history.append(epoch_loss)\n",
        "            \n",
        "\n",
        "            print('{} Loss: {:.4f}'.format(\n",
        "                phase, epoch_loss))\n",
        "            \n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < low_loss:\n",
        "                print(\"saving best model......\")\n",
        "                low_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                #torch.save(best_model_wts,\"/content/drive/My Drive/image memorability/saved models/resnet50_weights(2).pt\")\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # load best model weights\n",
        "    original_model =copy.deepcopy(model)\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model,original_model,running_loss_history,val_running_loss_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk__PUlQHhYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMUMCRUg95Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#idenetity block\n",
        "class IdentityBlock(nn.Module):\n",
        "    def __init__(self,f,in_channels,filters):\n",
        "        super(IdentityBlock,self).__init__()\n",
        "        '''\n",
        "        Args:\n",
        "        \n",
        "        f -- integer specifying the shape of window\n",
        "        in_channels : number of channels of input to this identity block\n",
        "        filters - list of integers (len=3 ) count of feature maps to be produced\n",
        "        \n",
        "        Returns \n",
        "        X -- output of the identity block,tensor of shape (n_H,n_W,n_C)\n",
        "        '''\n",
        "        self.in_channels = in_channels\n",
        "        self.kernel_size = f\n",
        "        self.F1 = filters[0]\n",
        "        self.F2 = filters[1]\n",
        "        self.F3 = filters[2]\n",
        "        #first component \n",
        "        self.conv1 = self.conv_layer(in_channels=self.in_channels,out_channels=self.F1,kernel_size=(1,1),padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(self.F1)\n",
        "        #second component\n",
        "        self.conv2 = self.conv_layer(in_channels=self.F1,out_channels=self.F2,kernel_size=(self.kernel_size,self.kernel_size),padding=\"same\")\n",
        "        self.bn2 = nn.BatchNorm2d(self.F2)\n",
        "        #third component\n",
        "        self.conv3 = self.conv_layer(in_channels=self.F2,out_channels=self.F3,kernel_size=(1,1),padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(self.F3)\n",
        "\n",
        "        \n",
        "    def conv_layer(self,in_channels,out_channels,kernel_size,padding=0,stride=1):\n",
        "        '''\n",
        "        Args:\n",
        "           in_channels : the number of input channel from the  input tensor\n",
        "           out_channels : the number of output channels of the feature map \n",
        "           kernel_size  : filter size \n",
        "           padding      : that takes two values [same ,0]\"[default : 0]\n",
        "           stride       : the stride length [default is zero]\n",
        "\n",
        "        Output:\n",
        "            convolution layer\n",
        "        '''\n",
        "  \n",
        "        if padding==\"same\":\n",
        "            padding = int((kernel_size[0]-1)/2)\n",
        "        return nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x_shortcut = x\n",
        "      #  print(\"first\",x_shortcut.shape,x.shape)\n",
        "      #  x = self.conv_layer(in_channels=x.shape[1] , out_channels=self.F1,kernel_size=(1,1),padding=0)(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "       # print(\"after 1\",x.shape)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x =  F.relu(x)\n",
        "        #print(\"after 2\",x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        #print(\"after 3\",x.shape)\n",
        "        #print(x_shortcut.shape)\n",
        "        x = x + x_shortcut\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        return x\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP1cIpBY995j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convolutional block\n",
        "class ConvolutionalBlock(nn.Module):\n",
        "    '''\n",
        "    Args:\n",
        "    f           : the size of filter that will be used in the intermediate layers of this convolutional block\n",
        "    in_channels : the number of input channels from the input tensor\n",
        "    filters      :  list of integers (len=3 ) count of feature maps to be produced\n",
        "    stride      : the length of stride\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    def __init__(self,f,in_channels,filters,stride=2):\n",
        "        super(ConvolutionalBlock,self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.kernel_size = f\n",
        "        self.F1 = filters[0]\n",
        "        self.F2 = filters[1]\n",
        "        self.F3 = filters[2]\n",
        "        self.stride = stride\n",
        "        #first component\n",
        "        self.conv1 = self.conv_layer(self.in_channels,self.F1,(1,1),padding=0,stride=self.stride)\n",
        "        self.bn1 = nn.BatchNorm2d(self.F1)\n",
        "        \n",
        "        #second component\n",
        "        self.conv2 = self.conv_layer(self.F1,self.F2,(f,f),padding=\"same\")\n",
        "        self.bn2 = nn.BatchNorm2d(self.F2)\n",
        "        \n",
        "        #third componenet\n",
        "        self.conv3 = self.conv_layer(self.F2,self.F3,(1,1))\n",
        "        self.bn3 = nn.BatchNorm2d(self.F3)\n",
        "        \n",
        "        #shortcut component\n",
        "        self.sconv = self.conv_layer(self.in_channels,self.F3,(1,1),padding=0,stride=self.stride)\n",
        "        self.sbn = nn.BatchNorm2d(self.F3)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        \n",
        "        x_shortcut = x\n",
        "#         print(x_shortcut.shape)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        \n",
        "        #\n",
        "        #print(x_shortcut.shape)\n",
        "        x_shortcut = self.sconv(x_shortcut)\n",
        "\n",
        "        x_shortcut = self.sbn(x_shortcut)\n",
        "        \n",
        "        x = x+x_shortcut\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "        \n",
        "        \n",
        "    def conv_layer(self,in_channels,out_channels,kernel_size,padding=0,stride=1):\n",
        "        '''\n",
        "        Args:\n",
        "           in_channels : the number of input channel from the  input tensor\n",
        "           out_channels : the number of output channels of the feature map \n",
        "           kernel_size  : filter size \n",
        "           padding      : that takes two values [same ,0]\"[default : 0]\n",
        "           stride       : the stride length [default is zero]\n",
        "        \n",
        "        Output:\n",
        "            Convolutional layer\n",
        "        '''\n",
        "        if padding==\"same\":\n",
        "            padding = int((kernel_size[0]-1)/2)\n",
        "        return nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,stride)\n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0KP_lIi-Bed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet50(nn.Module):\n",
        "    \n",
        "    def __init__(self,in_channels,identity_block,convolutional_block):\n",
        "        super(ResNet50,self).__init__()\n",
        "        \n",
        "        self.in_channels = in_channels\n",
        "        self.convolutional_block = convolutional_block\n",
        "        self.identity_block = identity_block\n",
        "        \n",
        "        #stage1\n",
        "        self.stage1_conv = self.conv_layer(self.in_channels,64,(7,7),padding=0,stride=2)\n",
        "        self.stage1_bn = nn.BatchNorm2d(64)\n",
        "        self.stage1_maxpool = nn.MaxPool2d(kernel_size=(3,3),stride=(2,2))\n",
        "  \n",
        "        #stage2\n",
        "        self.stage2_convblock = self.convolutional_block(3,64,[64,64,256],1)\n",
        "        self.stage2_identity_block1 = self.identity_block(3,256,[64,64,256])\n",
        "        # self.stage2_identity_block2 = self.identity_block(3,256,[64,64,256])\n",
        "        \n",
        "        #stage3\n",
        "        self.stage3_convblock = self.convolutional_block(3,256,[128,128,512])\n",
        "        self.stage3_identity_block1 = self.identity_block(3,512,[128,128,512])\n",
        "        # self.stage3_identity_block2 = self.identity_block(3,512,[128,128,512])\n",
        "        # self.stage3_identity_block3 = self.identity_block(3,512,[128,128,512])\n",
        "        \n",
        "        # #stage 4\n",
        "        self.stage4_convblock = self.convolutional_block(3,512,[128,128,1024])\n",
        "        self.stage4_identity_block1 = self.identity_block(3,1024,[128,128,1024])\n",
        "        # self.stage4_identity_block2 = self.identity_block(3,1024,[128,128,1024])\n",
        "        # self.stage4_identity_block3 = self.identity_block(3,1024,[128,128,1024])\n",
        "        # self.stage4_identity_block4 = self.identity_block(3,1024,[128,128,1024])\n",
        "        # self.stage4_identity_block5 = self.identity_block(3,1024,[128,128,1024])\n",
        "        \n",
        "        # #stage5\n",
        "        # self.stage5_convblock = self.convolutional_block(3,1024,[512,512,2048])\n",
        "        # self.stage5_identity_block1 = self.identity_block(3,2048,[512,512,2048])\n",
        "        # self.stage5_identity_block2 = self.identity_block(3,2048,[512,512,2048])\n",
        "        #pooling\n",
        "        # self.average_pool = nn.AvgPool2d((2,2))\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(1024,1)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        #stage1\n",
        "        x = self.stage1_conv(x)\n",
        "        x = self.stage1_bn(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.stage1_maxpool(x)\n",
        "        \n",
        "        #stage2\n",
        "        x = self.stage2_convblock(x)\n",
        "        x = self.stage2_identity_block1(x)\n",
        "        # x = self.stage2_identity_block2(x)\n",
        "        \n",
        "        #stage3\n",
        "        x = self.stage3_convblock(x)\n",
        "        x = self.stage3_identity_block1(x)\n",
        "        # x = self.stage3_identity_block2(x)\n",
        "        # x = self.stage3_identity_block3(x)\n",
        "        \n",
        "        # #stage4\n",
        "        x = self.stage4_convblock(x)\n",
        "        x = self.stage4_identity_block1(x)\n",
        "        # x = self.stage4_identity_block2(x)\n",
        "        # x = self.stage4_identity_block3(x)\n",
        "        # x = self.stage4_identity_block4(x)\n",
        "        # x = self.stage4_identity_block5(x)\n",
        "        \n",
        "        # #stage5\n",
        "        # x = self.stage5_convblock(x)\n",
        "        # x = self.stage5_identity_block1(x)\n",
        "        # x = self.stage5_identity_block2(x)\n",
        "        \n",
        "        #pooling\n",
        "        # x = self.average_pool(x)\n",
        "        x = self.gap(x)\n",
        "        print(x.shape)\n",
        "        x = x.squeeze()\n",
        "        if len(x.shape)==1:\n",
        "            print(\"single element\")\n",
        "            x = x.unsqueeze(0)\n",
        "\n",
        "        #fully connected \n",
        "        x = self.fc(x)\n",
        "        print(x.shape)\n",
        "        \n",
        "        \n",
        "    \n",
        "        \n",
        "\n",
        "    def conv_layer(self,in_channels,out_channels,kernel_size,padding=0,stride=1):\n",
        "        if padding==\"same\":\n",
        "            padding = int((kernel_size[0]-1)/2)\n",
        "        return nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_h2-c1zEwxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VRNet(nn.Module):\n",
        "    \n",
        "    def __init__(self,in_channels,identity_block,convolutional_block):\n",
        "        super(VRNet,self).__init__()\n",
        "        \n",
        "        self.in_channels = in_channels\n",
        "        self.convolutional_block = convolutional_block\n",
        "        self.identity_block = identity_block\n",
        "        \n",
        "        #stage1\n",
        "        self.stage1_conv = self.conv_layer(self.in_channels,64,(7,7),padding=0,stride=2)\n",
        "        self.stage1_bn = nn.BatchNorm2d(64)\n",
        "        self.stage1_maxpool = nn.MaxPool2d(kernel_size=(3,3),stride=(2,2))\n",
        "        \n",
        "        self.stage1_interconv3x3 = self.conv_layer(64,64,(3,3),padding=0,stride = 2)\n",
        "        self.stage1_interpool = nn.AdaptiveAvgPool2d(64)\n",
        "        self.stage1_intercon1x1 = self.conv_layer(64,32,(1,1),padding=0,stride =2)\n",
        "        \n",
        "        #stage2\n",
        "        self.stage2_convblock = self.convolutional_block(3,64,[64,64,256],1)\n",
        "        self.stage2_identity_block1 = self.identity_block(3,256,[64,64,256])\n",
        "        self.stage2_identity_block2 = self.identity_block(3,256,[64,64,256])\n",
        "        \n",
        "        self.stage2_interconv3x3 = self.conv_layer(256,64,(3,3),padding=0,stride = 2)\n",
        "        self.stage2_interpool = nn.AdaptiveAvgPool2d(64)\n",
        "        self.stage2_intercon1x1 = self.conv_layer(64,32,(1,1),padding=0,stride =2)\n",
        "\n",
        "        #stage3\n",
        "        self.stage3_convblock = self.convolutional_block(3,256,[128,128,512])\n",
        "        self.stage3_identity_block1 = self.identity_block(3,512,[128,128,512])\n",
        "        self.stage3_identity_block2 = self.identity_block(3,512,[128,128,512])\n",
        "        # self.stage3_identity_block3 = self.identity_block(3,512,[128,128,512])\n",
        "        \n",
        "        self.stage3_interconv3x3 = self.conv_layer(512,128,(3,3),padding=0,stride = 2)\n",
        "        self.stage3_interpool = nn.AdaptiveAvgPool2d(64)\n",
        "        self.stage3_intercon1x1 = self.conv_layer(128,64,(1,1),padding=0,stride =2)\n",
        "        \n",
        "        # #stage 4\n",
        "        # self.stage4_convblock = self.convolutional_block(3,512,[128,128,1024])\n",
        "        # self.stage4_identity_block1 = self.identity_block(3,1024,[128,128,1024])\n",
        "        # self.stage4_identity_block2 = self.identity_block(3,1024,[128,128,1024])\n",
        "        # self.stage4_identity_block3 = self.identity_block(3,1024,[128,128,1024])\n",
        "        # self.stage4_identity_block4 = self.identity_block(3,1024,[128,128,1024])\n",
        "        # self.stage4_identity_block5 = self.identity_block(3,1024,[128,128,1024])\n",
        "        \n",
        "        # self.stage4_interconv3x3 = self.conv_layer(1024,128,(3,3),padding=0,stride = 0)\n",
        "        # self.stage4_interpool = nn.AdaptiveAvgPool2d(64)\n",
        "        # self.stage4_intercon1x1 = self.conv_layer(128,64,(1,1),padding=0,stride =0)\n",
        "        \n",
        "        # #stage5\n",
        "        # self.stage5_convblock = self.convolutional_block(3,1024,[512,512,2048])\n",
        "        # self.stage5_identity_block1 = self.identity_block(3,2048,[512,512,2048])\n",
        "        # self.stage5_identity_block2 = self.identity_block(3,2048,[512,512,2048])\n",
        "        \n",
        "        # self.stage5_interconv3x3 = self.conv_layer(2048,128,(3,3),padding=0,stride = 0)\n",
        "        # self.stage5_interpool = nn.AdaptiveAvgPool2d(64)\n",
        "        # self.stage5_intercon1x1 = self.conv_layer(128,64,(1,1),padding=0,stride =0)\n",
        "        \n",
        "        #final conv\n",
        "        self.final_conv1x1 = self.conv_layer((32+32+64),64,(1,1),padding=0,stride=2)\n",
        "        self.final_conv3x3 = self.conv_layer(64,128,(3,3),padding=0,stride=2)\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(128,1)\n",
        "       \n",
        "        \n",
        "    def forward(self,x):\n",
        "        #stage1\n",
        "        x = self.stage1_conv(x)\n",
        "        x = self.stage1_bn(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.stage1_maxpool(x)\n",
        "        stage1_inter = x\n",
        "        #stage1 inter\n",
        "        stage1_inter= self.stage1_interconv3x3(stage1_inter)\n",
        "        stage1_inter = self.stage1_interpool(stage1_inter)\n",
        "        stage1_inter = self.stage1_intercon1x1(stage1_inter)\n",
        "        \n",
        "        \n",
        "        #stage2\n",
        "        x = self.stage2_convblock(x)\n",
        "        x = self.stage2_identity_block1(x)\n",
        "        x = self.stage2_identity_block2(x)\n",
        "        stage2_inter = x\n",
        "        stage2_inter= self.stage2_interconv3x3(stage2_inter)\n",
        "        stage2_inter = self.stage2_interpool(stage2_inter)\n",
        "        stage2_inter = self.stage2_intercon1x1(stage2_inter)\n",
        "        \n",
        "        \n",
        "        # stage3\n",
        "        x = self.stage3_convblock(x)\n",
        "        x = self.stage3_identity_block1(x)\n",
        "        x = self.stage3_identity_block2(x)\n",
        "        # x = self.stage3_identity_block3(x)\n",
        "        #stage3 inter\n",
        "        # stage3_inter = x\n",
        "        x = self.stage3_interconv3x3(x)\n",
        "        x = self.stage3_interpool(x)\n",
        "        x = self.stage3_intercon1x1(x)\n",
        "        \n",
        "        # #stage4\n",
        "        # x = self.stage4_convblock(x)\n",
        "        # x = self.stage4_identity_block1(x)\n",
        "        # x = self.stage4_identity_block2(x)\n",
        "        # x = self.stage4_identity_block3(x)\n",
        "        # x = self.stage4_identity_block4(x)\n",
        "        # x = self.stage4_identity_block5(x)\n",
        "        # #stage4\n",
        "        # stage4_inter = x\n",
        "        # stage4_inter= self.stage4_interconv3x3(stage4_inter)\n",
        "        # stage4_inter = self.stage4_interpool(stage4_inter)\n",
        "        # stage4_inter = self.stage4_intercon1x1(stage4_inter)\n",
        "        \n",
        "        # #stage5\n",
        "        # x = self.stage5_convblock(x)\n",
        "        # x = self.stage5_identity_block1(x)\n",
        "        # x = self.stage5_identity_block2(x)\n",
        "        # #stage5 inter\n",
        "        # stage5_inter = x\n",
        "        # stage5_inter= self.stage5_interconv3x3(stage5_inter)\n",
        "        # stage5_inter = self.stage5_interpool(stage5_inter)\n",
        "        # stage5_inter = self.stage5_intercon1x1(stage5_inter)\n",
        "        \n",
        "        #concatenate all feature maps\n",
        "        # concatenated_maps = torch.cat((stage1_inter,stage2_inter,stage3_inter,stage4_inter,stage5_inter),1)\n",
        "        concatenated_maps = torch.cat((stage1_inter,stage2_inter,x),1)\n",
        "        #final stage\n",
        "        concatenad_maps = self.final_conv1x1(concatenated_maps)\n",
        "        concatenad_maps = self.final_conv3x3(concatenad_maps)\n",
        "        concatenad_maps = self.final_pool(concatenad_maps)\n",
        "        concatenad_maps = concatenad_maps.squeeze()\n",
        "        if len(concatenad_maps.shape)==1:\n",
        "            concatenad_maps = concatenad_maps.unsqueeze(0)\n",
        "            \n",
        "        output = self.fc(concatenad_maps)\n",
        "        return output\n",
        "       \n",
        "        \n",
        "        \n",
        "    \n",
        "        \n",
        "\n",
        "    def conv_layer(self,in_channels,out_channels,kernel_size,padding=0,stride=1):\n",
        "        if padding==\"same\":\n",
        "            padding = int((kernel_size[0]-1)/2)\n",
        "        return nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj1A-bir-HIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet =VRNet(3,IdentityBlock,ConvolutionalBlock).to(device).double()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj8YsAfvM-0u",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naWEB4a5M_WK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.rand([32,3,22,22]).to(device).double()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMGQ4s0wIYvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(resnet.parameters(), lr = 0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPf-SfINxJrs",
        "colab_type": "code",
        "outputId": "0f9c1430-213e-41b6-d64f-332bad5c6680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_model,model,running_loss_history,val_running_loss_history = train_model(best_model,criterion,optimizer,exp_lr_scheduler,1)\n",
        "# torch.save(best_model.state_dict(),\"/content/drive/My Drive/image memorability/saved models/Vnet_weights(2).pt\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VRNet(\n",
              "  (stage1_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2))\n",
              "  (stage1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (stage1_maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (stage1_interconv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (stage1_interpool): AdaptiveAvgPool2d(output_size=64)\n",
              "  (stage1_intercon1x1): Conv2d(64, 32, kernel_size=(1, 1), stride=(2, 2))\n",
              "  (stage2_convblock): ConvolutionalBlock(\n",
              "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (sconv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (sbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (stage2_identity_block1): IdentityBlock(\n",
              "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (stage2_identity_block2): IdentityBlock(\n",
              "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (stage2_interconv3x3): Conv2d(256, 64, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (stage2_interpool): AdaptiveAvgPool2d(output_size=64)\n",
              "  (stage2_intercon1x1): Conv2d(64, 32, kernel_size=(1, 1), stride=(2, 2))\n",
              "  (stage3_convblock): ConvolutionalBlock(\n",
              "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), dilation=(2, 2))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (sconv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), dilation=(2, 2))\n",
              "    (sbn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (stage3_identity_block1): IdentityBlock(\n",
              "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (stage3_identity_block2): IdentityBlock(\n",
              "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (stage3_interconv3x3): Conv2d(512, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (stage3_interpool): AdaptiveAvgPool2d(output_size=64)\n",
              "  (stage3_intercon1x1): Conv2d(128, 64, kernel_size=(1, 1), stride=(2, 2))\n",
              "  (final_conv1x1): Conv2d(128, 64, kernel_size=(1, 1), stride=(2, 2))\n",
              "  (final_conv3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (final_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9O_0u0D-Rjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.rand([128,3,224,224]).to(device).double()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0A0o5FS-yaC",
        "colab_type": "code",
        "outputId": "fd63a6e0-20d8-471d-ead3-0f61e7b682c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a =resnet(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9xzRQAS-1aO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmNVl55r-NLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lstm with cnn "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U8dVDDEJ0OF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}